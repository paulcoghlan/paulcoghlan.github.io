<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>paulcoghlan.github.io</title><link>/</link><description>Recent content on paulcoghlan.github.io</description><generator>Hugo -- gohugo.io</generator><language>en-gb</language><lastBuildDate>Sun, 20 Feb 2022 14:38:12 +0000</lastBuildDate><atom:link href="/index.xml" rel="self" type="application/rss+xml"/><item><title>Add Audio Delay to MacOS OBS</title><link>/posts/add-audio-delay-obs/</link><pubDate>Sun, 20 Feb 2022 14:38:12 +0000</pubDate><guid>/posts/add-audio-delay-obs/</guid><description>Unsynchronised audio and video is annoying and fatiguing on long Zoom calls. Unfortunately using the OBS Virtual Camera feature will add latency to your video feed, so you need add an appropriate audio delay.
There are two established MacOS tools for adding an audio loopback (Loopback and Soundflower) but they both require the installation of a MacOS kernel extension - which I wasn&amp;rsquo;t able to do because of the Mobile Device Manager app installed by my employer.</description><content>&lt;p>Unsynchronised audio and video is annoying and fatiguing on long Zoom calls. Unfortunately using the OBS
Virtual Camera feature will add latency to your video feed, so you need add an appropriate audio delay.&lt;/p>
&lt;p>There are two established MacOS tools for adding an audio loopback (&lt;a href="https://rogueamoeba.com/loopback/">Loopback&lt;/a> and
&lt;a href="https://github.com/mattingalls/Soundflower">Soundflower&lt;/a>) but they both require the installation of a MacOS kernel extension -
which I wasn&amp;rsquo;t able to do because of the Mobile Device Manager app installed by my employer.&lt;/p>
&lt;p>&lt;a href="https://github.com/ExistentialAudio/BlackHole">BlackHole&lt;/a> is open source and fortunately doesn&amp;rsquo;t require a kernel extension to be installed.&lt;/p>
&lt;p>I was able to use BlackHole with OBS to add an audio delay as follows:&lt;/p>
&lt;ol>
&lt;li>Install BlackHole (&lt;code>brew install blackhole-2ch&lt;/code>)&lt;/li>
&lt;li>Set &lt;code>BlackHole 2ch&lt;/code> to be the &lt;code>Monitoring Device&lt;/code> in audio Settings:
&lt;figure class="left" >
&lt;img src="/2022/monitor.png" />
&lt;/figure>
&lt;/li>
&lt;li>Click on the &amp;ldquo;Advanced Audio Properties&amp;rdquo; cog to add a delay to your audio device:
&lt;figure class="left" >
&lt;img src="/2022/cog.png" style="width: 320px;" />
&lt;/figure>
&lt;/li>
&lt;li>Set &lt;code>Audio Monitoring&lt;/code> to &lt;code>Monitor Only (mute output)&lt;/code> and alter &lt;code>Sync Offset&lt;/code> to set the audio delay
&lt;figure class="left" >
&lt;img src="/2022/delay.png" />
&lt;/figure>
&lt;/li>
&lt;li>Use &lt;code>BlackHole 2ch&lt;/code> as the input audio device in your video call software, e.g. for Zoom:
&lt;figure class="left" >
&lt;img src="/2022/microphone.png" />
&lt;/figure>
&lt;/li>
&lt;/ol>
&lt;p>You can join a test video call on another device and use something like a metronome app to figure out the necessary audio delay. I used &lt;a href="https://apps.apple.com/ee/app/tempus-a-touch-screen-metronome/id955594935">Tempus&lt;/a> on my iPhone to flash the screen/make a sound at a regular interval.&lt;/p></content></item><item><title>Tips for using AWS Lambda Runtime Interface Emulator</title><link>/posts/using-aws-lambda-rie/</link><pubDate>Tue, 15 Feb 2022 18:29:26 +0000</pubDate><guid>/posts/using-aws-lambda-rie/</guid><description>Scenario I&amp;rsquo;ve found the AWS Lambda Runtime Interface Emulator (RIE) to be a very useful tool to help develop custom Docker images for AWS Lambdas - but I&amp;rsquo;ve not seen it mentioned much in blogs or StackOverflow, etc.
My scenario was that I needed to develop a service to read a SQS message containing a HTML link, convert the HTML to PDF, and upload the PDF to S3.
I was using wkhtmltopdf HTML to PDF convertor (basically a headless Chrome Browser), with some SQS/S3 integration glue code in Kotlin to align with the rest of the codebase.</description><content>&lt;h2 id="scenario">Scenario&lt;/h2>
&lt;p>I&amp;rsquo;ve found the &lt;a href="https://github.com/aws/aws-lambda-runtime-interface-emulator">AWS Lambda Runtime Interface Emulator&lt;/a> (RIE) to be a very useful tool to help develop custom Docker
images for AWS Lambdas - but I&amp;rsquo;ve not seen it mentioned much in blogs or StackOverflow, etc.&lt;/p>
&lt;p>My scenario was that I needed to develop a service to read a SQS message containing a HTML link,
convert the HTML to PDF, and upload the PDF to S3.&lt;/p>
&lt;p>I was using &lt;code>wkhtmltopdf&lt;/code> HTML to PDF convertor (basically a headless Chrome Browser), with some SQS/S3
integration glue code in Kotlin to align with the rest of the codebase.&lt;/p>
&lt;figure class="left" >
&lt;img src="/2022/convertor.png" style="width: 320px;" />
&lt;/figure>
&lt;h2 id="why-use-a-lambda-with-a-custom-docker-image">Why use a Lambda with a custom Docker image?&lt;/h2>
&lt;p>The easiest option to creating an AWS Lambda is to upload a ZIP file archive containing a raw Python,
Java, etc app. However:&lt;/p>
&lt;ul>
&lt;li>You might want to use a runtime that AWS doesnâ€™t currently support&lt;/li>
&lt;li>Or youâ€™re running 3rd-party binaries (e.g &lt;code>wkhtmltopdf&lt;/code> HTML-&amp;gt; PDF convertor, which
is fussy about Qt libraries)&lt;/li>
&lt;/ul>
&lt;h2 id="how-to-use-a-custom-docker-image">How to use a custom Docker image&lt;/h2>
&lt;p>Your AWS Lambda can trigger an executable in a Docker container. Either:&lt;/p>
&lt;ul>
&lt;li>Base on a AWS-provided image with Runtime Interface Client (RIC) already included - see &lt;a href="https://docs.aws.amazon.com/lambda/latest/dg/runtimes-images.html#runtimes-images-lp">https://docs.aws.amazon.com/lambda/latest/dg/runtimes-images.html#runtimes-images-lp&lt;/a>&lt;/li>
&lt;li>Or create your own custom image, but add a &lt;a href="https://docs.aws.amazon.com/lambda/latest/dg/runtimes-images.html#runtimes-api-client">Runtime Image Client&lt;/a> (RIC) to interface Lambda services to your function code
e.g. for a Java Gradle build, add the following dependency:&lt;br>
&lt;code>implementation(&amp;quot;com.amazonaws:aws-lambda-java-runtime-interface-client:1.0.0&amp;quot;)&lt;/code>&lt;/li>
&lt;/ul>
&lt;h2 id="why-develop-locally">Why develop locally?&lt;/h2>
&lt;p>The main reason to develop images locally is that it offers a much faster development cycle - there
is no need to upload images to S3!&lt;/p>
&lt;p>Logging issues following on from an incorrect Docker config are often easier to debug locally because
you can change the &lt;code>Dockerfile&lt;/code> and see the effects almost immediately. You can also inspect
the container itself as it is running on your local host.&lt;/p>
&lt;h2 id="how-to-use-the-aws-runtime-interface-emulator-with-your-custom-image">How to use the AWS Runtime Interface Emulator with your custom image&lt;/h2>
&lt;p>To recap: if you are using a custom Docker image you need a &lt;a href="https://docs.aws.amazon.com/lambda/latest/dg/runtimes-images.html#runtimes-api-client">Runtime Image Client&lt;/a> (RIC) included in the deployed application.&lt;/p>
&lt;p>Additionally if you are developing locally you need a &lt;a href="https://github.com/aws/aws-lambda-runtime-interface-emulator/">Runtime Interface Emulator&lt;/a> to expose a fake Lambda HTTP endpoint. This RIE can be used
to trigger your function and verify that it will work as desired when it is deployed to AWS services.&lt;/p>
&lt;p>I always find a diagram helps in these situations. The figure below compares the architecture of a
real AWS Lambda function running in the cloud against an emulated local one running on your PC or laptop:&lt;/p>
&lt;figure class="left" >
&lt;img src="/2022/localdev.png" />
&lt;/figure>
&lt;p>The steps are as follows:&lt;/p>
&lt;ul>
&lt;li>Mount AWS Runtime Interface Emulator (RIE) directory and specify com.amazonaws.services.lambda.runtime.api.client.AWSLambda entrypoint:&lt;/li>
&lt;/ul>
&lt;div class="collapsable-code">
&lt;input id="1" type="checkbox" />
&lt;label for="1">
&lt;span class="collapsable-code__language">sh&lt;/span>
&lt;span class="collapsable-code__toggle" data-label-expand="â–³" data-label-collapse="â–½">&lt;/span>
&lt;/label>
&lt;pre class="language-sh" >&lt;code>
# Install RIE - provides fake Lambda HTTP endpoint to trigger your function
mkdir -p ~/.aws-lambda-rie &amp;amp;&amp;amp; \
curl -Lo ~/.aws-lambda-rie/aws-lambda-rie https://github.com/aws/aws-lambda-runtime-interface-emulator/releases/latest/download/aws-lambda-rie &amp;amp;&amp;amp; \
chmod &amp;#43;x ~/.aws-lambda-rie/aws-lambda-rie
&lt;/code>&lt;/pre>
&lt;/div>
&lt;ul>
&lt;li>Run Docker image containing target function (&lt;code>lambdas:latest&lt;/code> in this instance):&lt;/li>
&lt;/ul>
&lt;div class="collapsable-code">
&lt;input id="2" type="checkbox" />
&lt;label for="2">
&lt;span class="collapsable-code__language">sh&lt;/span>
&lt;span class="collapsable-code__toggle" data-label-expand="â–³" data-label-collapse="â–½">&lt;/span>
&lt;/label>
&lt;pre class="language-sh" >&lt;code>
docker run -v ~/.aws-lambda-rie:/aws-lambda \
--entrypoint /aws-lambda/aws-lambda-rie -p 9000:8080 lambdas:latest /usr/bin/java \
-cp &amp;#39;.*:/opt/java/generate_pdf.jar&amp;#39; \
com.amazonaws.services.lambda.runtime.api.client.AWSLambda lambdas.generatepdf.GeneratePDF::handleRequest
&lt;/code>&lt;/pre>
&lt;/div>
&lt;ul>
&lt;li>Finally, you can invoke your Lambda function via the RIE endpoint:&lt;/li>
&lt;/ul>
&lt;div class="collapsable-code">
&lt;input id="3" type="checkbox" />
&lt;label for="3">
&lt;span class="collapsable-code__language">sh&lt;/span>
&lt;span class="collapsable-code__toggle" data-label-expand="â–³" data-label-collapse="â–½">&lt;/span>
&lt;/label>
&lt;pre class="language-sh" >&lt;code>
curl -XPOST &amp;#34;http://localhost:9000/2015-03-31/functions/function/invocations&amp;#34; -d &amp;#39;{}&amp;#39;
&lt;/code>&lt;/pre>
&lt;/div>
&lt;h2 id="conclusion">Conclusion&lt;/h2>
&lt;ul>
&lt;li>Lambdas are great - here weâ€™ve isolated a 3rd party binary from the rest of our application infrastructure ðŸš€&lt;/li>
&lt;li>The AWS RIE framework is useful if you have Lambda config issues&lt;/li>
&lt;/ul>
&lt;h2 id="some-tips">Some tips&lt;/h2>
&lt;ul>
&lt;li>Watch out for Dockerfile ENTRYPOINT vs CMD! ðŸ¦¶ðŸ”« - see &lt;a href="http://aws.amazon.com/blogs/opensource/demystifying-entrypoint-cmd-docker/">http://aws.amazon.com/blogs/opensource/demystifying-entrypoint-cmd-docker/&lt;/a>&lt;/li>
&lt;li>You can quickly check that how your environment variables are setup from:&lt;/li>
&lt;/ul>
&lt;div class="collapsable-code">
&lt;input id="4" type="checkbox" />
&lt;label for="4">
&lt;span class="collapsable-code__language">sh&lt;/span>
&lt;span class="collapsable-code__toggle" data-label-expand="â–³" data-label-collapse="â–½">&lt;/span>
&lt;/label>
&lt;pre class="language-sh" >&lt;code>
docker inspect --format=&amp;#39;{{range .Config.Env}}{{println .}}{{end}}&amp;#39; &amp;lt;image&amp;gt;
&lt;/code>&lt;/pre>
&lt;/div></content></item><item><title>Coming soon</title><link>/reviews/my-first-review/</link><pubDate>Tue, 08 Feb 2022 12:32:35 +0100</pubDate><guid>/reviews/my-first-review/</guid><description/><content/></item><item><title>Ikea Homestudio Lights</title><link>/posts/ikea-homestudio-lights/</link><pubDate>Thu, 09 Sep 2021 16:34:28 +0100</pubDate><guid>/posts/ikea-homestudio-lights/</guid><description>I&amp;rsquo;ve built an automated home studio lighting setup for less than $100 which I believe produces more flattering images whilst being unobtrusive enough to look part of a typical desk environment.
My setup is based on two $39/Â£29 IKEA Skurup desk lamps.
I bought some Osram Zigbee E14 LED lights from Amazon UK when they were discounted to Â£4.49, and with the help of a vice I very carefully popped the plastic cover off:</description><content>&lt;p>I&amp;rsquo;ve built an automated home studio lighting setup for less than $100 which I believe produces more flattering images whilst being unobtrusive enough to look
part of a typical desk environment.&lt;/p>
&lt;p>My setup is based on two $39/Â£29 &lt;a href="https://www.ikea.com/gb/en/p/skurup-work-wall-lamp-black-80471143/">IKEA Skurup&lt;/a> desk lamps.&lt;/p>
&lt;p>I bought some Osram Zigbee E14 LED lights from &lt;a href="https://www.amazon.co.uk/gp/product/B0747VDHG3">Amazon UK&lt;/a> when they were discounted to Â£4.49, and
with the help of a vice I very carefully popped the plastic cover off:&lt;/p>
&lt;p>&lt;img src="/2021/IMG_4514.jpg" alt="Osram lamp with top cover off">&lt;/p>
&lt;p>(notice there are two bits of glue on the cover - maybe a heat gun would have made it easier?)&lt;/p>
&lt;p>Here&amp;rsquo;s what the modified bulb looks like in the lamp:
&lt;img src="/2021/no-cover.jpg" alt="Bulb in situ">&lt;/p>
&lt;p>I ordered a 3mm thick acrylic disc cut to the measured size of the lamp interior (117mm) from &lt;a href="https://www.simplyplastics.com/catalog/discs/cast-acrylic-round-discs/led-light-diffusing-opal-acrylic-disc/c-24/c-93/p-962">SimplyPlastics&lt;/a>. I think the result isn&amp;rsquo;t too shabby:&lt;/p>
&lt;p>&lt;img src="/2021/finished-product.jpg" alt="Ikea lamp with diffuser">&lt;/p>
&lt;p>Here are some comparison pics:&lt;/p>
&lt;figure class="left" >
&lt;img src="/2021/original-lamp.jpg" />
&lt;/figure>
&lt;figure class="left" >
&lt;img src="/2021/with-disc.jpg" />
&lt;/figure>
&lt;figure class="left" >
&lt;img src="/2021/20w-led.jpg" />
&lt;/figure>
&lt;p>The great thing about using Zigbee lights is that I can automate the whole setup and control all of the lights and the camera from a button (I&amp;rsquo;m using &lt;a href="https://www.home-assistant.io/">Home Assistant&lt;/a>. The lights can be automatically configured to the correct color temperature for the time of day. More to come on that in another post!&lt;/p></content></item><item><title>Diy Teleprompter</title><link>/posts/diy-teleprompter/</link><pubDate>Wed, 01 Sep 2021 15:34:58 +0100</pubDate><guid>/posts/diy-teleprompter/</guid><description>Being able to look someone in the eye is something we take for granted when we meet someone face-to-face, but this is tricky with desktop monitors.
I wanted a compact, inexpensive teleprompter to fit between my two desktop monitors to show me my Zoom window and look directly at my webcam.
The problem with the less expensive teleprompter models is that they tend to be made of plastic, and so unable to support anything heavier than a tablet/phone.</description><content>&lt;p>Being able to look someone in the eye is something we take for granted when we meet someone face-to-face, but this is tricky with desktop monitors.&lt;/p>
&lt;p>I wanted a compact, inexpensive teleprompter to fit between my two desktop monitors to show me my Zoom window and look directly at my webcam.&lt;br>
The problem with the less expensive teleprompter models is that they tend to be made of plastic, and so unable to support anything heavier than a tablet/phone.&lt;/p>
&lt;p>My solution was to mount a &lt;a href="https://www.amazon.co.uk/gp/product/B076CBHMQM/">7&amp;quot; field monitor&lt;/a> to my monitor stand and attach the &lt;a href="https://www.aliexpress.com/item/4001323460983.html">telepromter&lt;/a> to that.&lt;/p>
&lt;p>&lt;img src="/2021/teleprompter.jpg" alt="Teleprompter">&lt;/p>
&lt;p>I&amp;rsquo;ve found SmallRig components to be excellent value and quality. I used a &lt;a href="https://www.amazon.co.uk/gp/product/B076HLBZDX/">Magic Arm&lt;/a> and &lt;a href="https://www.amazon.co.uk/gp/product/B00CIHRKM4/">Cool Cheese Bar&lt;/a> to attach everything to a monitor mount. I also added some Sugru (blue!) to keep the teleprompter stable.&lt;/p>
&lt;p>I still need to tidy up the cabling a bit, but otherwise I&amp;rsquo;m really happy with the solution.&lt;/p></content></item><item><title>About</title><link>/about/</link><pubDate>Fri, 09 Jul 2021 12:00:45 +0100</pubDate><guid>/about/</guid><description>Public brain-dump of all of the things I&amp;rsquo;m working on.
My main interests: software development (Java, Scala and Go), home automation (Raspberry Pi, ESP32), home entertainment, digital health/wellbeing, photography and video production.
How to contact me:
Github https://github.com/paulcoghlan Linkedin https://www.linkedin.com/in/pgcoghlan</description><content>&lt;p>Public brain-dump of all of the things I&amp;rsquo;m working on.&lt;/p>
&lt;p>My main interests: software development (Java, Scala and Go), home automation (Raspberry Pi, ESP32),
home entertainment, digital health/wellbeing, photography and video production.&lt;/p>
&lt;p>How to contact me:&lt;/p>
&lt;ul>
&lt;li>Github &lt;a href="https://github.com/paulcoghlan">https://github.com/paulcoghlan&lt;/a>&lt;/li>
&lt;li>Linkedin &lt;a href="https://www.linkedin.com/in/pgcoghlan">https://www.linkedin.com/in/pgcoghlan&lt;/a>&lt;/li>
&lt;/ul></content></item><item><title>My First Post</title><link>/posts/my-first-post/</link><pubDate>Thu, 08 Jul 2021 12:32:35 +0100</pubDate><guid>/posts/my-first-post/</guid><description/><content/></item></channel></rss>